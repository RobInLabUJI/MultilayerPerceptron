{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOODLdDvX8CyIXSBN/l6Vf4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobInLabUJI/MultilayerPerceptron/blob/main/Traffic_Sign_Classification_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traffic Sign Classification: Training\n",
        "\n",
        "Our dataset comes from [**GTSRB** - The German Traffic Sign Recognition Benchmark](https://benchmark.ini.rub.de/gtsrb_news.html). It contains more than 40 classes and more than 50,000 images of traffic signs, which are prepared for multi-class, single-image classification challenge. Based  on it we'll build a simple classifier."
      ],
      "metadata": {
        "id": "ajVeyDa3lYO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0xbrxZplJut"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "TMP_DATA_DIR = \"dataset/tmp\"\n",
        "TMP_LABELS_DIR = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Test\")\n",
        "\n",
        "TRAINING_DATA_DIR = \"dataset/training\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fetch images from GTSRB website\n",
        "#Images for training\n",
        "!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n",
        "#Labels for validation\n",
        "!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip"
      ],
      "metadata": {
        "id": "aUofr7mqluJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "mhAo6AT4mwzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "to_unpack = [\n",
        "    (\"GTSRB_Final_Training_Images.zip\", TMP_DATA_DIR),\n",
        "    (\"GTSRB_Final_Test_GT.zip\", TMP_LABELS_DIR)\n",
        "]\n",
        " \n",
        "for file, directory in to_unpack:\n",
        "    print(\"Unzipping {} to {}...\".format(file, directory))\n",
        "    with zipfile.ZipFile(file,\"r\") as zip_ref:\n",
        "        zip_ref.extractall(directory)"
      ],
      "metadata": {
        "id": "9-btvM0BmD1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare training and labels\n",
        "\n",
        "Originally dataset operates on numerical labels (e.g. \"00000\"). Let's make it human-readable. Labels will be saved in `/output` directory."
      ],
      "metadata": {
        "id": "AqpiQcjNmcHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_ROOT_DIR = \"output/\"\n",
        "OUTPUT_LABELS = os.path.join(OUTPUT_ROOT_DIR, \"retrained_labels_mv1_100_224.txt\")\n",
        "OUTPUT_READABLE_LABELS = os.path.join(OUTPUT_ROOT_DIR, \"labels_readable.txt\")"
      ],
      "metadata": {
        "id": "7bTbS7FamP8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    0: '20_speed',\n",
        "    1: '30_speed',\n",
        "    2: '50_speed',\n",
        "    3: '60_speed',\n",
        "    4: '70_speed',\n",
        "    5: '80_speed',\n",
        "    6: '80_lifted',\n",
        "    7: '100_speed',\n",
        "    8: '120_speed',\n",
        "    9: 'no_overtaking_general',\n",
        "    10: 'no_overtaking_trucks',\n",
        "    11: 'right_of_way_crossing',\n",
        "    12: 'right_of_way_general',\n",
        "    13: 'give_way',\n",
        "    14: 'stop',\n",
        "    15: 'no_way_general',\n",
        "    16: 'no_way_trucks',\n",
        "    17: 'no_way_one_way',\n",
        "    18: 'attention_general',\n",
        "    19: 'attention_left_turn',\n",
        "    20: 'attention_right_turn',\n",
        "    21: 'attention_curvy',\n",
        "    22: 'attention_bumpers',\n",
        "    23: 'attention_slippery',\n",
        "    24: 'attention_bottleneck',\n",
        "    25: 'attention_construction',\n",
        "    26: 'attention_traffic_light',\n",
        "    27: 'attention_pedestrian',\n",
        "    28: 'attention_children',\n",
        "    29: 'attention_bikes',\n",
        "    30: 'attention_snowflake',\n",
        "    31: 'attention_deer',\n",
        "    32: 'lifted_general',\n",
        "    33: 'turn_right',\n",
        "    34: 'turn_left',\n",
        "    35: 'turn_straight',\n",
        "    36: 'turn_straight_right',\n",
        "    37: 'turn_straight_left',\n",
        "    38: 'turn_right_down',\n",
        "    39: 'turn_left_down',\n",
        "    40: 'turn_circle',\n",
        "    41: 'lifted_no_overtaking_general',\n",
        "    42: 'lifted_no_overtaking_trucks'\n",
        "}\n",
        "\n",
        "if not os.path.exists(OUTPUT_ROOT_DIR):\n",
        "        os.makedirs(OUTPUT_ROOT_DIR)\n",
        "\n",
        "file = open(OUTPUT_READABLE_LABELS, 'w')\n",
        "for key, val in sorted(label_map.items()):\n",
        "    file.write(\"{}\\n\".format(val))\n",
        "file.close()"
      ],
      "metadata": {
        "id": "gW26DyEenJ-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only tricky part of GTSRB dataset is that images are stored as [*.ppm](https://en.wikipedia.org/wiki/Netpbm_format) files, which aren't supported by TensorFlow by default. To make it possible we need to convert them to .jpg files."
      ],
      "metadata": {
        "id": "g2uaAxyMnRE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all PPM files and their labels\n",
        "\n",
        "tmp_train_data_dir = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Training/Images\")\n",
        "\n",
        "# Get all subdirectories of data_dir. Each represents a label.\n",
        "directories = [d for d in os.listdir(tmp_train_data_dir) \n",
        "               if os.path.isdir(os.path.join(tmp_train_data_dir, d))]\n",
        "# Loop through the label directories and collect the data in two lists, labels and images.\n",
        "ppm_files_train = []\n",
        "ppm_labels_train = []\n",
        "for class_directory in directories:\n",
        "    label_dir = os.path.join(tmp_train_data_dir, class_directory)\n",
        "    file_names = [os.path.join(label_dir, f) \n",
        "                  for f in os.listdir(label_dir) if f.endswith(\".ppm\")]\n",
        "    # For each label, load it's images and add them to the images list.\n",
        "    # And add the label number (i.e. directory name) to the labels list.\n",
        "    for image_file in file_names:\n",
        "        ppm_files_train.append(image_file)\n",
        "        ppm_labels_train.append(class_directory)\n",
        "        \n",
        "# Let's have it sorted for better debugging.\n",
        "ppm_files_train.sort()\n",
        "ppm_labels_train.sort()"
      ],
      "metadata": {
        "id": "hW7DlhzWnLbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "xOKho3dXnlbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Convert\n",
        "# from: dataset/Final_Training/Images/00000/00000_00000.ppm\n",
        "# to:   dataset/training/00000/00000_00000.jpg\n",
        "\n",
        "for ppm_file, label in zip(ppm_files_train, ppm_labels_train):\n",
        "    image = Image.open(ppm_file)\n",
        "    directory = os.path.join(TRAINING_DATA_DIR, label)\n",
        "    image_filename = \"{}.jpg\".format(os.path.splitext(os.path.basename(ppm_file))[0])\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    \n",
        "    image.save(os.path.join(directory, image_filename))"
      ],
      "metadata": {
        "id": "Z5e7snU-ngSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print all categories with an example image for each of them."
      ],
      "metadata": {
        "id": "34IklyZ8n0qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y-gQ3L42n9l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_training_dirs = [d for d in os.listdir(TRAINING_DATA_DIR) \n",
        "               if os.path.isdir(os.path.join(TRAINING_DATA_DIR, d))]\n",
        "preprocessed_training_dirs.sort()\n",
        "\n",
        "training_images = []\n",
        "for training_dir in preprocessed_training_dirs:\n",
        "    training_images.append(os.path.join(TRAINING_DATA_DIR, training_dir, \"00000_00000.jpg\"))\n",
        "\n",
        "i = 0\n",
        "plt.figure(figsize=(17, 30))\n",
        "for image in training_images:\n",
        "    plt.subplot(10,7, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"{}\".format(label_map[i]))\n",
        "    i += 1\n",
        "    plt.imshow(Image.open(image))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AgMMhNN5nmra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of TensorFlow's image modules expect float inputs in the `[0, 1]` range. Use the `ImageDataGenerator`'s `rescale` parameter to achieve this.\n",
        "The image size will be handled later."
      ],
      "metadata": {
        "id": "KmBDgRvfoMcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-sYijXifodA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "image_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
        "image_data = image_generator.flow_from_directory(str(TRAINING_DATA_DIR), target_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "Q6sZrUAXn_iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting object is an iterator that returns image_batch, label_batch pairs."
      ],
      "metadata": {
        "id": "fTErTA7kouQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, label_batch in image_data:\n",
        "  print(\"Image batch shape: \", image_batch.shape)\n",
        "  print(\"Label batch shape: \", label_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "slmwpVEvogdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "### Create model"
      ],
      "metadata": {
        "id": "5dlPLXwOpRmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\" #@param {type:\"string\"}\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                         input_shape=(224,224,3))\n",
        "\n",
        "feature_batch = feature_extractor_layer(image_batch)\n",
        "\n",
        "print(feature_batch.shape)"
      ],
      "metadata": {
        "id": "szM2E_42pFd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_layer.trainable = False"
      ],
      "metadata": {
        "id": "IZ0KpIkiq5I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  keras.layers.Dense(image_data.num_classes)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-iA34mdurESr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer=keras.optimizers.Adam(),\n",
        "  loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])"
      ],
      "metadata": {
        "id": "gFHDONp3rPuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CollectBatchStats(keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.batch_losses = []\n",
        "    self.batch_acc = []\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    self.batch_losses.append(logs['loss'])\n",
        "    self.batch_acc.append(logs['acc'])\n",
        "    self.model.reset_metrics()"
      ],
      "metadata": {
        "id": "eV3malM4rbry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
        " \n",
        "batch_stats_callback = CollectBatchStats()\n",
        " \n",
        "history = model.fit(image_data, epochs=20,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks=[batch_stats_callback])"
      ],
      "metadata": {
        "id": "ZURHrBkvriyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(batch_stats_callback.batch_losses);"
      ],
      "metadata": {
        "id": "2IIp-bZirqeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(batch_stats_callback.batch_acc);"
      ],
      "metadata": {
        "id": "JcHjsvIFrso9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the trained model"
      ],
      "metadata": {
        "id": "fovc_vdFp3xF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"output/model{}\".format(int(t))\n",
        "model.save(export_path, save_format='tf')\n",
        "\n",
        "export_path"
      ],
      "metadata": {
        "id": "sD7pr6Cdp0vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the files (tested in Google Chrome, won't work with Firefox)."
      ],
      "metadata": {
        "id": "tHN92luJqHR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! tar czf {export_path + \".tar.gz\"} {export_path}"
      ],
      "metadata": {
        "id": "t3JPFhg4rUX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(export_path + \".tar.gz\")"
      ],
      "metadata": {
        "id": "TahrRo7Zp7sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it, congratulations! :-)"
      ],
      "metadata": {
        "id": "IYBVWo6vtdAF"
      }
    }
  ]
}