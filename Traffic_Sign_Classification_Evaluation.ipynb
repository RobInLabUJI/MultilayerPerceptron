{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPkS/cQBGC8ed+68yKzoX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobInLabUJI/MultilayerPerceptron/blob/main/Traffic_Sign_Classification_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traffic Sign Classification: Validation\n",
        "\n",
        "Our dataset comes from [**GTSRB** - The German Traffic Sign Recognition Benchmark](https://benchmark.ini.rub.de/gtsrb_news.html). It contains more than 40 classes and more than 50,000 images of traffic signs, which are prepared for multi-class, single-image classification challenge. Based  on it we'll build a simple classifier."
      ],
      "metadata": {
        "id": "ajVeyDa3lYO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0xbrxZplJut"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "TMP_DATA_DIR = \"dataset/tmp\"\n",
        "TMP_LABELS_DIR = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Test\")\n",
        "\n",
        "TESTING_DATA_DIR = \"dataset/testing\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fetch images deom GTSRB website\n",
        "#Images for validation    \n",
        "!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip\n",
        "#Labels for validation\n",
        "!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip"
      ],
      "metadata": {
        "id": "aUofr7mqluJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "mhAo6AT4mwzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "to_unpack = [\n",
        "    (\"GTSRB_Final_Test_Images.zip\", TMP_DATA_DIR),\n",
        "    (\"GTSRB_Final_Test_GT.zip\", TMP_LABELS_DIR)\n",
        "]\n",
        " \n",
        "for file, directory in to_unpack:\n",
        "    print(\"Unzipping {} to {}...\".format(file, directory))\n",
        "    with zipfile.ZipFile(file,\"r\") as zip_ref:\n",
        "        zip_ref.extractall(directory)"
      ],
      "metadata": {
        "id": "9-btvM0BmD1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare validation and labels\n",
        "\n",
        "Originally dataset operates on numerical labels (e.g. \"00000\"). Let's make it human-readable. Labels will be saved in `/output` directory."
      ],
      "metadata": {
        "id": "AqpiQcjNmcHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_ROOT_DIR = \"output/\"\n",
        "OUTPUT_LABELS = os.path.join(OUTPUT_ROOT_DIR, \"retrained_labels_mv1_100_224.txt\")\n",
        "OUTPUT_READABLE_LABELS = os.path.join(OUTPUT_ROOT_DIR, \"labels_readable.txt\")"
      ],
      "metadata": {
        "id": "7bTbS7FamP8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    0: '20_speed',\n",
        "    1: '30_speed',\n",
        "    2: '50_speed',\n",
        "    3: '60_speed',\n",
        "    4: '70_speed',\n",
        "    5: '80_speed',\n",
        "    6: '80_lifted',\n",
        "    7: '100_speed',\n",
        "    8: '120_speed',\n",
        "    9: 'no_overtaking_general',\n",
        "    10: 'no_overtaking_trucks',\n",
        "    11: 'right_of_way_crossing',\n",
        "    12: 'right_of_way_general',\n",
        "    13: 'give_way',\n",
        "    14: 'stop',\n",
        "    15: 'no_way_general',\n",
        "    16: 'no_way_trucks',\n",
        "    17: 'no_way_one_way',\n",
        "    18: 'attention_general',\n",
        "    19: 'attention_left_turn',\n",
        "    20: 'attention_right_turn',\n",
        "    21: 'attention_curvy',\n",
        "    22: 'attention_bumpers',\n",
        "    23: 'attention_slippery',\n",
        "    24: 'attention_bottleneck',\n",
        "    25: 'attention_construction',\n",
        "    26: 'attention_traffic_light',\n",
        "    27: 'attention_pedestrian',\n",
        "    28: 'attention_children',\n",
        "    29: 'attention_bikes',\n",
        "    30: 'attention_snowflake',\n",
        "    31: 'attention_deer',\n",
        "    32: 'lifted_general',\n",
        "    33: 'turn_right',\n",
        "    34: 'turn_left',\n",
        "    35: 'turn_straight',\n",
        "    36: 'turn_straight_right',\n",
        "    37: 'turn_straight_left',\n",
        "    38: 'turn_right_down',\n",
        "    39: 'turn_left_down',\n",
        "    40: 'turn_circle',\n",
        "    41: 'lifted_no_overtaking_general',\n",
        "    42: 'lifted_no_overtaking_trucks'\n",
        "}\n",
        "\n",
        "if not os.path.exists(OUTPUT_ROOT_DIR):\n",
        "        os.makedirs(OUTPUT_ROOT_DIR)\n",
        "\n",
        "file = open(OUTPUT_READABLE_LABELS, 'w')\n",
        "for key, val in sorted(label_map.items()):\n",
        "    file.write(\"{}\\n\".format(val))\n",
        "file.close()"
      ],
      "metadata": {
        "id": "gW26DyEenJ-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "xOKho3dXnlbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y-gQ3L42n9l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of TensorFlow's image modules expect float inputs in the `[0, 1]` range. Use the `ImageDataGenerator`'s `rescale` parameter to achieve this.\n",
        "\n",
        "The image size will be handled later."
      ],
      "metadata": {
        "id": "KmBDgRvfoMcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-sYijXifodA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "image_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "Q6sZrUAXn_iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the validation dataset from *.ppm to *.jpg."
      ],
      "metadata": {
        "id": "ylIvh1Loo1mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load testing set\n",
        "tmp_test_data_dir = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Test/Images\")"
      ],
      "metadata": {
        "id": "q-cymsQvox_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "tmp_test_data_files = [f for f in os.listdir(tmp_test_data_dir) if f.endswith(\".ppm\")]\n",
        "test_images = []\n",
        "\n",
        "#export as JPGs\n",
        "for ppm_file in tmp_test_data_files:\n",
        "    image_dir = os.path.join(tmp_test_data_dir, ppm_file) \n",
        "    image = Image.open(image_dir)\n",
        "    directory = TESTING_DATA_DIR\n",
        "    image_filename = \"{}.jpg\".format(os.path.splitext(os.path.basename(ppm_file))[0])\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "    final_image = os.path.join(directory, image_filename)\n",
        "    image.save(final_image)\n",
        "\n",
        "    test_images.append(final_image)\n",
        "    test_images.sort()\n",
        "    \n",
        "print(\"Test images count:\", len(test_images))"
      ],
      "metadata": {
        "id": "03Qx003xpDSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "lDnogvZcrtKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "XP-pcaSQONci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace the filename with the appropriate value."
      ],
      "metadata": {
        "id": "XWdq990zWuUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf model1675845690.tar.gz"
      ],
      "metadata": {
        "id": "HuVF2ZjQOh_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('output/model1675845690')"
      ],
      "metadata": {
        "id": "omYj55MUPnGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformation of the evaluation dataset\n",
        "\n",
        "Load the validation data from the CSV file into a pandas data frame. \n",
        "Also change the file ending from *.ppm to *.jpg in the `Filename` column.\n",
        "Then also rescale the values for the model. \n",
        "The `ClassId` must be a string and with leading zeros, because this classification naming was also used for the subfolders in the training dataset. "
      ],
      "metadata": {
        "id": "PnAebmxBmbER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "tmp_test_labels_csv = os.path.join(TMP_LABELS_DIR, \"GT-final_test.csv\")\n",
        "test_data_frame = pd.read_csv(tmp_test_labels_csv, header=0, sep=';')\n",
        "test_data_frame['Filename'] = test_data_frame['Filename'].str.replace('.ppm','.jpg')\n",
        "test_data_frame['ClassId'] = test_data_frame['ClassId'].astype(str).str.zfill(5)\n",
        "\n",
        "image_test_data = image_generator.flow_from_dataframe(test_data_frame, x_col=\"Filename\", directory=TESTING_DATA_DIR, y_col=\"ClassId\", target_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "2eNjgIq0ruik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_test_batch, label_test_batch in image_test_data:\n",
        "  print(\"Image batch shape: \", image_test_batch.shape)\n",
        "  print(\"Label batch shape: \", label_test_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "twWDm7gCoshI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display some prediction result\n",
        "\n",
        "\n",
        "Run one image batch through the model and extract the predicted traffic sign ID. \n"
      ],
      "metadata": {
        "id": "Q4OMpJQrpIZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_batch = model.predict(image_test_batch)\n",
        "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
        "label_id = np.argmax(label_test_batch, axis=-1)"
      ],
      "metadata": {
        "id": "SZ_UonBZpGZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the images in one batch with the prediction result. \n",
        "Print the accuracy for the displayed batch. "
      ],
      "metadata": {
        "id": "RatddJRRpQ7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = image_test_batch.shape[0]\n",
        "num_plot_column = 5\n",
        "num_plot_row = batch_size // num_plot_column + (batch_size % num_plot_column > 0)\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(batch_size):\n",
        "  plt.subplot(num_plot_row,num_plot_column,n+1)\n",
        "  plt.imshow(image_test_batch[n])\n",
        "  color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
        "  plt.title(label_map[predicted_id[n]].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")\n",
        "\n",
        "print(\"Accuracy of the shown eval batch:\")\n",
        "accuracy_score(label_id, predicted_id)"
      ],
      "metadata": {
        "id": "7LJsSUx6pNh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate validation dataset metrics \n",
        "\n",
        "Calculate the prediction accuracy and loss for all images in the test dataset"
      ],
      "metadata": {
        "id": "eTUgjLQEplIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x=image_test_data, batch_size=image_test_data.batch_size, steps=image_test_data.samples/image_test_data.batch_size)\n",
        "print(\"Loss: \", score[0], \"Accuracy: \", score[1])\n"
      ],
      "metadata": {
        "id": "7Q4HvN-6pgsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it, congratulations! :-)"
      ],
      "metadata": {
        "id": "IYBVWo6vtdAF"
      }
    }
  ]
}